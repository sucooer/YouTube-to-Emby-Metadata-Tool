import os
import sys
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
import shutil
import requests
import xml.etree.ElementTree as ET
import re  # ç”¨äºæ­£åˆ™è¡¨è¾¾å¼è§£æ
from yt_dlp import YoutubeDL
import tkinter as tk
from tkinter import filedialog
import subprocess
import importlib.util
import zipfile
import tarfile
import tempfile

def get_app_dir():
    if hasattr(sys, '_MEIPASS'):
        return sys._MEIPASS
    return os.path.abspath(os.path.dirname(__file__))

sys.path.insert(0, get_app_dir())

def sanitize_filename(title):
    return "".join(c for c in title if c not in '\\/*?:"<>|').strip()

def get_video_info(url, cookie_file=None):
    # ç¡®ä¿ URL æ ¼å¼æ­£ç¡®
    if 'youtube.com/watch?v=' in url:
        video_id = url.split('watch?v=')[-1].split('&')[0]
        url = f'https://www.youtube.com/watch?v={video_id}'
    
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': False,
        'force_ipv4': True,
        'socket_timeout': 30,  # å¢åŠ è¶…æ—¶æ—¶é—´
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept-Language': 'en-US,en;q=0.9'
        },
        'format': 'best',  # ä½¿ç”¨æœ€ä½³æ ¼å¼
        'retries': 10,  # å¢åŠ é‡è¯•æ¬¡æ•°
        'cookiefile': os.path.expandvars(cookie_file.strip('"')) if cookie_file else None
    }
    
    try:
        if cookie_file:
            print(f"â„¹ï¸ Using cookie file: {ydl_opts['cookiefile']}")
        print(f"âŒ› æ­£åœ¨è·å–è§†é¢‘ä¿¡æ¯: {url}")
        
        with YoutubeDL(ydl_opts) as ydl:
            print("ğŸ“‹ è·å–å¯ç”¨æ ¼å¼åˆ—è¡¨...")
            info = ydl.extract_info(url, download=False)
            
            if not info:
                raise Exception("æ— æ³•è·å–è§†é¢‘ä¿¡æ¯")
                
            # æ‰“å°è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            print(f"\nğŸ“º è§†é¢‘æ ‡é¢˜: {info.get('title', 'Unknown')}")
            print(f"ğŸ‘¤ ä¸Šä¼ è€…: {info.get('uploader', 'Unknown')}")
            
            # è·å–æ ¼å¼åˆ—è¡¨
            formats = info.get('formats', [])
            if not formats:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è§†é¢‘æ ¼å¼")
            else:
                print("\nğŸ¥ å¯ç”¨çš„è§†é¢‘æ ¼å¼ï¼š")
                for f in formats:
                    format_id = f.get('format_id', 'N/A')
                    ext = f.get('ext', 'N/A')
                    resolution = f.get('resolution', 'N/A')
                    filesize = f.get('filesize', 0)
                    if filesize:
                        filesize = f"{filesize/1024/1024:.1f}MB"
                    else:
                        filesize = 'N/A'
                    print(f"ID: {format_id}, æ ¼å¼: {ext}, åˆ†è¾¨ç‡: {resolution}, å¤§å°: {filesize}")
            
            # å…¶ä½™ä»£ç ä¿æŒä¸å˜
            upload_date = info.get('upload_date', '')
            return {
                'title': sanitize_filename(info.get('title', 'No Title')),
                'description': info.get('description', ''),
                'uploader': info.get('uploader', 'Unknown'),
                'publish_date': f"{upload_date[:4]}-{upload_date[4:6]}-{upload_date[6:8]}" if upload_date else "",
                'year': upload_date[:4] if upload_date else "",
                'thumbnail_url': info.get('thumbnail', ''),
                'tags': info.get('tags', []),
                'url': url,
                'formats': formats,
                'original_info': info
            }
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {str(e)}")
        print("\nğŸ’¡ æç¤ºï¼š")
        print("1. æ£€æŸ¥è§†é¢‘ URL æ˜¯å¦å®Œæ•´")
        print("2. ç¡®è®¤è§†é¢‘æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®")
        print("3. å°è¯•æ›´æ–° yt-dlp:")
        print("   python -m pip install -U yt-dlp")
        print("4. æ‰‹åŠ¨æµ‹è¯•è§†é¢‘æ ¼å¼:")
        print(f"   yt-dlp --list-formats {url}")
        return None

def download_video(info, output_dir):
    """ä¸‹è½½è§†é¢‘æ–‡ä»¶"""
    try:
        video_format = info.get('video_format', 'mp4')
        ydl_opts = {
            'format': f'bestvideo+bestaudio/best',
            'merge_output_format': video_format,
            'socket_timeout': 30,  # å¢åŠ è¶…æ—¶æ—¶é—´
            'force_ipv4': True,  # å¼ºåˆ¶ä½¿ç”¨ IPv4
            'http_chunk_size': 10485760,  # åˆ†å—ä¸‹è½½ï¼Œä¼˜åŒ–ç½‘ç»œè¯·æ±‚ï¼ˆ10MBï¼‰
            'cookiefile': info.get('cookiefile'),
            'outtmpl': os.path.join(output_dir, f"{info['title']}.%(ext)s"),
            'sleep_interval': 2,  # æ¯æ¬¡è¯·æ±‚é—´éš” 2 ç§’
            'max_sleep_interval': 5,  # æœ€å¤§éšæœºé—´éš” 5 ç§’
        }
        print(f"âŒ› Downloading video as {video_format} ...")
        with YoutubeDL(ydl_opts) as ydl:
            ydl.download([info['url']])
        # æŸ¥æ‰¾ä¸‹è½½åçš„è§†é¢‘æ–‡ä»¶
        downloaded_files = [f for f in os.listdir(output_dir) if f.startswith(info['title']) and f.endswith(f".{video_format}")]
        if not downloaded_files:
            raise Exception("No video file found after download")
        return downloaded_files[0]
    except Exception as e:
        print(f"âŒ Video download failed: {str(e)}")
        return None

def download_subtitles(info, output_dir):
    """ä¸‹è½½å­—å¹•æ–‡ä»¶å¹¶ä¿å­˜åˆ°ä¸è§†é¢‘æ–‡ä»¶ç›¸åŒçš„ç›®å½•ï¼Œä¼˜å…ˆä¸‹è½½æ—¥è¯­å’Œä¸­æ–‡å­—å¹•ï¼Œå¹¶è½¬æ¢ä¸º ASS æ ¼å¼"""
    try:
        ydl_opts = {
            'writesubtitles': True,  # å¯ç”¨å­—å¹•ä¸‹è½½
            'subtitleslangs': ['ja', 'zh-Hans', 'zh-Hant'],  # ä¼˜å…ˆä¸‹è½½æ—¥è¯­å’Œä¸­æ–‡å­—å¹•
            'subtitlesformat': 'ass/srt/vtt',  # ä¸‹è½½å­—å¹•æ ¼å¼ï¼Œä¼˜å…ˆ ASS
            'skip_download': True,  # ä»…ä¸‹è½½å­—å¹•ï¼Œä¸ä¸‹è½½è§†é¢‘
            'force_ipv4': True,  # å¼ºåˆ¶ä½¿ç”¨ IPv4
            'http_chunk_size': 10485760,  # åˆ†å—ä¸‹è½½ï¼Œä¼˜åŒ–ç½‘ç»œè¯·æ±‚ï¼ˆ10MBï¼‰
            'cookiefile': info.get('cookiefile'),  # ä½¿ç”¨ cookie æ–‡ä»¶ç»•è¿‡äººæœºéªŒè¯
            'outtmpl': os.path.join(output_dir, f"{info['title']}.%(ext)s"),
            'quiet': True,
            'no_warnings': True,
            'sleep_interval': 2,  # æ¯æ¬¡è¯·æ±‚é—´éš” 2 ç§’
            'max_sleep_interval': 5,  # æœ€å¤§éšæœºé—´éš” 5 ç§’
        }
        print("âŒ› Downloading subtitles...")
        with YoutubeDL(ydl_opts) as ydl:
            ydl.download([info['url']])

        # é‡å‘½åå­—å¹•æ–‡ä»¶ä»¥ç¬¦åˆ Emby åˆ®å‰Šè§„åˆ™ï¼ŒæŒ‰è¯­è¨€ä»£ç å‘½å
        found = False
        for file in os.listdir(output_dir):
            if file.startswith(info['title']) and file.endswith(('.ass', '.srt', '.vtt')):
                subtitle_path = os.path.join(output_dir, file)
                subtitle_ext = os.path.splitext(file)[1]
                # æå–è¯­è¨€ä»£ç 
                m = re.match(rf"^{re.escape(info['title'])}\.([a-zA-Z\-]+){subtitle_ext}$", file)
                lang = m.group(1) if m else None
                if subtitle_ext == '.vtt':
                    # å¦‚æœå­—å¹•æ˜¯ VTT æ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸º ASS æ ¼å¼
                    converted_file = os.path.splitext(subtitle_path)[0] + '.ass'
                    vtt_to_ass(subtitle_path, converted_file)
                    os.remove(subtitle_path)  # åˆ é™¤åŸå§‹ VTT æ–‡ä»¶
                    subtitle_path = converted_file
                    subtitle_ext = '.ass'
                if lang:
                    new_name = f"{os.path.splitext(info['title'])[0]}.{lang}{subtitle_ext}"
                else:
                    new_name = f"{os.path.splitext(info['title'])[0]}{subtitle_ext}"
                os.rename(subtitle_path, os.path.join(output_dir, new_name))
                print(f"âœ… Subtitle saved as: {new_name}")
                found = True
        if not found:
            print("âš ï¸ No subtitles found for this video.")
        return None
    except Exception as e:
        print(f"âš ï¸ Failed to download subtitles: {str(e)}")
        return None

def vtt_to_ass(vtt_path, ass_path):
    """å°† VTT æ ¼å¼å­—å¹•è½¬æ¢ä¸º ASS æ ¼å¼"""
    try:
        import webvtt
        from pysubs2 import SSAFile, SSAEvent
        import subprocess
        from . import get_ffmpeg_path

        print(f"âŒ› Converting {vtt_path} to ASS format...")
        subs = SSAFile()
        for caption in webvtt.read(vtt_path):
            start = caption.start_in_seconds * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            end = caption.end_in_seconds * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            text = caption.text.replace('\n', '\\N')  # æ›¿æ¢æ¢è¡Œç¬¦ä¸º ASS æ ¼å¼çš„æ¢è¡Œç¬¦
            event = SSAEvent(start=start, end=end, text=text)
            subs.events.append(event)  # æ·»åŠ å­—å¹•äº‹ä»¶
        subs.save(ass_path)
        print(f"âœ… Converted to ASS: {ass_path}")
    except ImportError as e:
        print("âš ï¸ Missing required module. Please install dependencies:")
        print("   pip install webvtt-py pysubs2")
        raise e
    except Exception as e:
        print(f"âš ï¸ Failed to convert VTT to ASS: {str(e)}")
        raise e

def generate_metadata_files(video_info, output_dir):
    base_name = os.path.splitext(video_info['title'])[0]
    thumbnail_path = os.path.join(output_dir, f"{base_name}-poster.jpg")
    if video_info['thumbnail_url']:
        try:
            print(f"âŒ› Downloading thumbnail from {video_info['thumbnail_url']}")
            # å¢åŠ é‡è¯•æœºåˆ¶å’Œè¶…æ—¶è®¾ç½®
            for attempt in range(3):  # å°è¯•æœ€å¤š 3 æ¬¡
                try:
                    response = requests.get(video_info['thumbnail_url'], timeout=10)
                    response.raise_for_status()
                    with open(thumbnail_path, 'wb') as f:
                        f.write(response.content)
                    print(f"âœ… Thumbnail saved to {thumbnail_path}")
                    break
                except requests.exceptions.RequestException as e:
                    print(f"âš ï¸ Attempt {attempt + 1} failed: {str(e)}")
                    if attempt == 2:  # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                        raise
        except Exception as e:
            print(f"âŒ Thumbnail download failed: {str(e)}")
    try:
        root = ET.Element("movie")
        ET.SubElement(root, "title").text = video_info['title']
        ET.SubElement(root, "plot").text = video_info['description']
        ET.SubElement(root, "premiered").text = video_info['publish_date']
        ET.SubElement(root, "year").text = video_info['year']
        ET.SubElement(root, "studio").text = "YouTube"

        if video_info['uploader']:
            director = ET.SubElement(root, "director")
            director.text = video_info['uploader']
        
        for tag in video_info.get('tags', [])[:10]:
            ET.SubElement(root, "tag").text = tag
        nfo_path = os.path.join(output_dir, f"{base_name}.nfo")
        ET.ElementTree(root).write(nfo_path, encoding='utf-8', xml_declaration=True)
        print(f"âœ… NFO file generated: {nfo_path}")
    except Exception as e:
        print(f"âŒ NFO generation failed: {str(e)}")

def get_ffmpeg_path():
    # ä¼˜å…ˆä½¿ç”¨é¡¹ç›®å†…çš„ffmpeg.exe
    local_ffmpeg = os.path.join(os.path.dirname(__file__), "tools", "ffmpeg.exe")
    if os.path.exists(local_ffmpeg):
        return local_ffmpeg
    # é€€å›åˆ°ç³»ç»ŸPATH
    return shutil.which("ffmpeg.exe" if os.name == "nt" else "ffmpeg")

def check_ffmpeg_installed():
    ffmpeg_path = get_ffmpeg_path()
    if not ffmpeg_path:
        print("âŒ ffmpeg is not installed or not in PATH or tools/ffmpeg.exe.")
        print("â„¹ï¸ You can download it from: https://ffmpeg.org/download.html")
        return False
    return True

def update_ytdlp():
    print("æ˜¯å¦éœ€è¦æ£€æŸ¥å¹¶è‡ªåŠ¨æ›´æ–° yt-dlpï¼Ÿ")
    choice = input("è¾“å…¥ y è¿›è¡Œæ›´æ–°ï¼Œç›´æ¥å›è½¦è·³è¿‡: ").strip().lower()
    if choice == "y":
        try:
            # ä¼˜å…ˆå°è¯• pip æ›´æ–°
            print("âŒ› æ­£åœ¨é€šè¿‡ pip æ›´æ–° yt-dlp ...")
            subprocess.check_call([sys.executable, "-m", "pip", "install", "-U", "yt-dlp"])
            print("âœ… yt-dlp å·²é€šè¿‡ pip æ›´æ–°")
        except Exception as e:
            print(f"âš ï¸ pip æ›´æ–°å¤±è´¥: {e}")
            # å¦‚æœ pip å¤±è´¥ï¼Œå°è¯• yt-dlp è‡ªå¸¦æ›´æ–°ï¼ˆé€‚ç”¨äº yt-dlp.exeï¼‰
            try:
                print("âŒ› æ­£åœ¨å°è¯• yt-dlp è‡ªå¸¦æ›´æ–° ...")
                subprocess.check_call(["yt-dlp", "-U"])
                print("âœ… yt-dlp å·²è‡ªæ›´æ–°")
            except Exception as e2:
                print(f"âŒ yt-dlp æ›´æ–°å¤±è´¥: {e2}")

def get_yt_dlp_install_path():
    # è·å–yt_dlpåŒ…çš„å®‰è£…è·¯å¾„
    spec = importlib.util.find_spec("yt_dlp")
    if spec and spec.submodule_search_locations:
        return spec.submodule_search_locations[0]
    return None

def get_current_ytdlp_version():
    try:
        from yt_dlp.version import __version__ as ytdlp_version
        return ytdlp_version
    except Exception:
        return None

def get_latest_stable_version():
    import requests
    r = requests.get("https://pypi.org/pypi/yt-dlp/json", timeout=10)
    return r.json()["info"]["version"]

def update_yt_dlp_in_app(version_type, log_func=print, github_token=None):
    import os, shutil, requests, tarfile, zipfile, tempfile
    yt_dlp_path = get_yt_dlp_dir()
    if not yt_dlp_path:
        log_func("æœªæ‰¾åˆ°yt_dlpå®‰è£…è·¯å¾„")
        return False

    repo = "yt-dlp-nightly-builds"
    api_url = f"https://api.github.com/repos/yt-dlp/{repo}/releases/latest"
    headers = {}
    if github_token:
        headers["Authorization"] = f"token {github_token}"
    try:
        # å…ˆè·å–æœ¬åœ°ç‰ˆæœ¬å·
        local_version = get_current_ytdlp_version()
        if local_version:
            log_func(f"yt-dlp å½“å‰ç‰ˆæœ¬ä¸º {local_version}ï¼Œå¦‚æ— ç‰¹æ®Šéœ€æ±‚æ— éœ€é¢‘ç¹æ›´æ–°ã€‚")
        try:
            r = requests.get(api_url, timeout=20, headers=headers)
            r.raise_for_status()
        except requests.exceptions.HTTPError as e:
            if e.response is not None and e.response.status_code == 403:
                log_func("GitHub API é™æµï¼Œæ— æ³•æ£€æµ‹æ–°ç‰ˆæœ¬ã€‚è¯·ç¨åå†è¯•ã€‚")
                return False
            else:
                log_func(f"yt-dlp nightly ç‰ˆæ›´æ–°å¤±è´¥: {e}")
                return False
        latest_version = r.json().get("tag_name")
        if local_version and latest_version and local_version == latest_version:
            log_func(f"yt-dlp å·²ç»æ˜¯æœ€æ–°ç‰ˆï¼ˆ{local_version}ï¼‰ï¼Œæ— éœ€æ›´æ–°ã€‚")
            return True
        assets = r.json().get("assets", [])
        url = None
        for asset in assets:
            if asset["name"].endswith(".tar.gz"):
                url = asset["browser_download_url"]
                break
        if not url:
            for asset in assets:
                if asset["name"].endswith(".zip"):
                    url = asset["browser_download_url"]
                    break
        if not url:
            log_func("æœªæ‰¾åˆ°å¯ç”¨çš„æºç åŒ…")
            return False
        log_func(f"æ­£åœ¨ä¸‹è½½ nightly ç‰ˆ yt-dlp ...")
        tmp_dir = tempfile.mkdtemp()
        local_file = os.path.join(tmp_dir, os.path.basename(url))
        with requests.get(url, stream=True, timeout=60) as r2:
            r2.raise_for_status()
            with open(local_file, "wb") as f:
                for chunk in r2.iter_content(1024 * 1024):
                    f.write(chunk)
        # è§£å‹
        if local_file.endswith(".tar.gz"):
            with tarfile.open(local_file, "r:gz") as tar:
                tar.extractall(tmp_dir)
        elif local_file.endswith(".zip"):
            with zipfile.ZipFile(local_file, "r") as zipf:
                zipf.extractall(tmp_dir)
        # æ‰¾åˆ°yt_dlpç›®å½•
        yt_dlp_src = None
        for root, dirs, files in os.walk(tmp_dir):
            if "yt_dlp" in dirs:
                yt_dlp_src = os.path.join(root, "yt_dlp")
                break
        if not yt_dlp_src:
            log_func("è§£å‹åæœªæ‰¾åˆ°yt_dlpç›®å½•")
            return False
        # è¦†ç›–
        if os.path.exists(yt_dlp_path):
            shutil.rmtree(yt_dlp_path)
        shutil.copytree(yt_dlp_src, yt_dlp_path)
        log_func(f"yt-dlp nightly ç‰ˆå·²æ›´æ–°ï¼Œè¯·é‡å¯åº”ç”¨ç”Ÿæ•ˆã€‚")
        shutil.rmtree(tmp_dir)
        return True
    except Exception as e:
        log_func(f"yt-dlp nightly ç‰ˆæ›´æ–°å¤±è´¥: {e}")
        return False

def get_yt_dlp_dir():
    if hasattr(sys, '_MEIPASS'):
        return os.path.join(sys._MEIPASS, 'yt_dlp')
    return os.path.join(os.path.abspath(os.path.dirname(__file__)), 'yt_dlp')

def main():
    update_ytdlp()
    print("====== YouTube to Emby Metadata Tool ======")
    # æ£€æŸ¥ ffmpeg æ˜¯å¦å·²å®‰è£…
    if not check_ffmpeg_installed():
        return
    youtube_url = input("Enter YouTube URL: ").strip()
    if not youtube_url.startswith(('http://', 'https://')):
        print("âŒ Invalid URL format")
        return

    base_output_dir = input("Base output directory (default: ./downloads): ").strip() or "./downloads"
    os.makedirs(base_output_dir, exist_ok=True)
    # é»˜è®¤ cookie æ–‡ä»¶è·¯å¾„
    default_cookie_path = os.path.expanduser("~\\cookies.txt")
    print(f"1. ä½¿ç”¨é»˜è®¤ cookie æ–‡ä»¶: {default_cookie_path}")
    print("2. æ‰‹åŠ¨é€‰æ‹© cookie æ–‡ä»¶")
    print("3. ä¸ä½¿ç”¨ cookie æ–‡ä»¶")
    cookie_choice = input("è¯·é€‰æ‹© cookie æ–‡ä»¶æ–¹å¼ï¼ˆ1/2/3ï¼Œé»˜è®¤1ï¼‰: ").strip() or "1"
    cookie_path = None
    if cookie_choice == "1":
        cookie_path = default_cookie_path
        if not os.path.exists(cookie_path):
            print(f"âš ï¸ Cookie file not found: {cookie_path}")
            cookie_path = None
    elif cookie_choice == "2":
        try:
            root = tk.Tk()
            root.withdraw()  # éšè—ä¸»çª—å£
            # å°†çª—å£æå‡åˆ°æœ€å‰
            root.attributes('-topmost', True)
            print("æ­£åœ¨æ‰“å¼€æ–‡ä»¶é€‰æ‹©çª—å£...")
            cookie_path = filedialog.askopenfilename(
                title="é€‰æ‹© cookies.txt æ–‡ä»¶",
                filetypes=[("Text Files", "*.txt"), ("All Files", "*.*")],
                parent=root  # è®¾ç½®çˆ¶çª—å£
            )
            if cookie_path:
                if not os.path.exists(cookie_path):
                    print("âš ï¸ æ‰€é€‰æ–‡ä»¶ä¸å­˜åœ¨")
                    cookie_path = None
                else:
                    print(f"âœ… å·²é€‰æ‹© cookie æ–‡ä»¶: {cookie_path}")
            else:
                print("âš ï¸ æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶")
                cookie_path = None
            root.destroy()  # é”€æ¯ Tk çª—å£
        except Exception as e:
            print(f"âš ï¸ æ‰“å¼€æ–‡ä»¶é€‰æ‹©çª—å£å¤±è´¥: {str(e)}")
            cookie_path = None
    else:
        cookie_path = None

    # æ–°å¢ï¼šé€‰æ‹©è§†é¢‘ä¿å­˜æ ¼å¼
    print("è¯·é€‰æ‹©ä¿å­˜è§†é¢‘çš„æ ¼å¼ï¼š")
    print("1. mp4ï¼ˆé»˜è®¤ï¼‰")
    print("2. mkv")
    format_choice = input("è¾“å…¥ 1 æˆ– 2ï¼ˆé»˜è®¤1ï¼‰: ").strip() or "1"
    if format_choice == "2":
        video_format = "mkv"
    else:
        video_format = "mp4"

    video_info = get_video_info(youtube_url, cookie_path)
    if not video_info:
        print("âŒ Failed to fetch metadata")
        return
    video_info['cookiefile'] = cookie_path
    video_info['video_format'] = video_format   # ä¼ é€’æ ¼å¼ä¿¡æ¯

    output_dir = os.path.join(base_output_dir, video_info['title'])
    os.makedirs(output_dir, exist_ok=True)
    print(f"ğŸ“ Created output folder: {output_dir}")

    video_filename = download_video(video_info, output_dir)
    if not video_filename:
        print("âŒ Failed to download video")
        return

    # ä¸‹è½½å­—å¹•
    download_subtitles(video_info, output_dir)

    generate_metadata_files(video_info, output_dir)
    print("\nğŸ‰ Success! Files created:")
    print(f"- Video: {os.path.join(output_dir, video_filename)}")
    print(f"- Metadata: {os.path.join(output_dir, video_info['title'])}.nfo")
    print(f"- Thumbnail: {os.path.join(output_dir, video_info['title'])}-poster.jpg")

if __name__ == "__main__":
    main()

